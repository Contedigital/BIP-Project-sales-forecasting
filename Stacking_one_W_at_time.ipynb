{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, time, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "%matplotlib inline\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    " \n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "figsize=(12,9)\n",
    "\n",
    "np.random.seed(238746)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SplitTestDate = \"2018-12-02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    #\"linear\" : LinearRegression(),\n",
    "    \"xgb\" : xgb.XGBRegressor(n_estimators=100, learning_rate=0.5),\n",
    "    \"forest\" : RandomForestRegressor(n_estimators=60,random_state=1234),\n",
    "    #\"ada\": AdaBoostRegressor(random_state=123, n_estimators=500)\n",
    "    #\"cat\": CatBoostRegressor(iterations=500,learning_rate=0.5,eval_metric='MAPE')\n",
    "}\n",
    "\n",
    "features_for_model = {\n",
    "\n",
    "    \"xgb\" : ['scaled_quarter','scaled_month','scaled_year','scaled_dayofyear','scaled_dayofmonth','scaled_weekofyear',\n",
    "             'scaled_price_diff1','scaled_price',\n",
    "             \"BRAND2\",\"BRAND4\",\n",
    "             'scaled_sales1','scaled_diff1','scaled_diff2','percentage_diff1',\n",
    "             \"scaled_rolling1\",\"scaled_rolling2\",\"scaled_rolling3\",\"scaled_rolling4\",\"scaled_rolling5\",\n",
    "             'scaled_promo'],\n",
    "    \"forest\": ['scaled_quarter','scaled_month','scaled_year','scaled_dayofyear','scaled_dayofmonth','scaled_weekofyear',\n",
    "             'scaled_price_diff1','scaled_price',\n",
    "            \"BRAND2\",\"BRAND4\",\n",
    "             'scaled_sales1','scaled_sales2','scaled_diff1','scaled_diff2','percentage_diff1',\n",
    "             \"scaled_rolling2\",\"scaled_rolling3\",\n",
    "             'scaled_promo'],\n",
    "    \"cat\": [\n",
    "             'scaled_price_diff1','scaled_price',\n",
    "            \"BRAND2\",\"BRAND4\",\n",
    "             'scaled_sales1','scaled_sales2','scaled_sales3','scaled_diff1','scaled_diff2','percentage_diff1',\n",
    "            ]\n",
    "}\n",
    "\n",
    "finalreg = xgb.XGBRegressor(n_estimators=500, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_transformer = preprocessing.QuantileTransformer(output_distribution='normal', random_state=123)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "def scale(feature, scaler = min_max_scaler):\n",
    "    size = len(feature)\n",
    "    return scaler.fit_transform(np.array([feature]).reshape(size, 1)).T[0]\n",
    "def unscale(scaled, original, scaler = min_max_scaler):\n",
    "    size2 = len(scaled)\n",
    "    size1 = len(original)\n",
    "    return scaler.fit(np.array([original]).reshape(size1, 1)).inverse_transform(np.array([scaled]).reshape(size2, 1)).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def plot_results(ytrue, prediction, label):\n",
    "    df_ytrue = pd.DataFrame(ytrue)\n",
    "    df_ytrue['predicted'] =  prediction \n",
    "    plt.plot(df_ytrue[label],label='data')\n",
    "    plt.plot(df_ytrue['predicted'],label='predicted')\n",
    "    plt.xticks(rotation=45)\n",
    "    mape = mean_absolute_percentage_error(df_ytrue[label],df_ytrue['predicted'])\n",
    "\n",
    "    plt.title(\"Forecasting on Test Set MAPE=%.3f\"%mape)\n",
    "    plt.legend();\n",
    "    plt.show()\n",
    "    return mape\n",
    "\n",
    "def scaled_mape(prediction, y_test, rescale):\n",
    "    results = pd.DataFrame(columns = [\"sku\",\"target\",\"prediction\"])\n",
    "\n",
    "    for sku in y_test[\"sku\"].unique():\n",
    "\n",
    "        pred_sku = prediction[np.where(y_test[\"sku\"] == sku)]\n",
    "        originals = rescale.loc[rescale[\"sku\"] == sku][\"target\"]\n",
    "        pred = unscale(pred_sku,originals)\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame({\n",
    "            \"date\" : y_test[y_test[\"sku\"] == sku][\"date\"],\n",
    "            \"sku\" : y_test[y_test[\"sku\"] == sku][\"sku\"],\n",
    "            \"scaled_target\" : y_test[y_test[\"sku\"] == sku][\"scaled_target\"],\n",
    "            \"target\" : y_test[y_test[\"sku\"] == sku][\"target\"],\n",
    "            \"scaled_prediction\" : pred_sku,\n",
    "            \"prediction\" : pred\n",
    "        })])\n",
    "    results = results.dropna().set_index(\"date\")\n",
    "    return mean_absolute_percentage_error(results[\"target\"],results[\"prediction\"])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_scaled_results(prediction, y_test, rescale):\n",
    "    results = pd.DataFrame(columns = [\"sku\",\"target\",\"prediction\"])\n",
    "\n",
    "    for sku in y_test[\"sku\"].unique():\n",
    "\n",
    "        pred_sku = prediction[np.where(y_test[\"sku\"] == sku)]\n",
    "        originals = rescale.loc[rescale[\"sku\"] == sku][\"target\"]\n",
    "        pred = unscale(pred_sku,originals)\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame({\n",
    "            \"date\" : y_test[y_test[\"sku\"] == sku][\"date\"],\n",
    "            \"sku\" : y_test[y_test[\"sku\"] == sku][\"sku\"],\n",
    "            \"scaled_target\" : y_test[y_test[\"sku\"] == sku][\"scaled_target\"],\n",
    "            \"target\" : y_test[y_test[\"sku\"] == sku][\"target\"],\n",
    "            \"scaled_prediction\" : pred_sku,\n",
    "            \"prediction\" : pred\n",
    "        })])\n",
    "    results = results.dropna().set_index(\"date\")\n",
    "\n",
    "    return plot_results(results[\"target\"], results[\"prediction\"], \"target\"), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_training(model,X,y,label = \"scaled_target\",span = 24):\n",
    "    \n",
    "    #k = number of folds\n",
    "    k = int(len(X_train)/span)\n",
    "    \n",
    "    prediction = pd.DataFrame(columns = [\"date\",\"sku\",\"pred\"])    \n",
    "    \n",
    "    for fold in range(0,k):\n",
    "        if fold != k - 1:\n",
    "            validation = X_train.iloc[fold*span:(fold+1)*span]\n",
    "        else:\n",
    "            validation = X_train.iloc[fold*span:]\n",
    "        \n",
    "        training = X_train[~X_train.index.isin(validation.index)]\n",
    "        y_tr  = y_train[~y_train.index.isin(validation.index)]\n",
    "        y_val  = y_train[y_train.index.isin(validation.index)]\n",
    "\n",
    "        model.fit(training, y_tr[label])\n",
    "        partial_pred = pd.DataFrame()\n",
    "        partial_pred[\"date\"] = y_val[\"date\"]\n",
    "        partial_pred[\"sku\"] = y_val[\"sku\"]\n",
    "        partial_pred[\"pred\"] = model.predict(validation)\n",
    "        partial_pred.set_index(validation.index)\n",
    "        prediction = prediction.append(partial_pred)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackingPred(models,final_model, X_train, y_train, X_test,y_test,features_for_model,rescale = None, span = 24, label = \"scaled_target\"):\n",
    "    final_prediction = []\n",
    "    for week in y_test.date.unique():\n",
    "        print(week)\n",
    "        test = X_test.loc[y_test.date == week]\n",
    "        #TRAIN SET PREDICTION WITH MODELS\n",
    "        results_dict = {}\n",
    "        for name, model in models.items():\n",
    "            X = X_train[features_for_model[name]]\n",
    "            results_dict.update({name : predict_training(model, X, y_train,\"scaled_target\",span)})\n",
    "\n",
    "        train_result = pd.DataFrame(index = y_train.index)\n",
    "        for name,r in results_dict.items():\n",
    "            train_result[\"date\"] = r[\"date\"]\n",
    "            train_result[\"sku\"] = r[\"sku\"]\n",
    "            train_result[name] = r[\"pred\"]\n",
    "\n",
    "        #TEST SET PREDICTION WITH MODELS\n",
    "        prediction_df = pd.DataFrame()\n",
    "        for name, model in models.items():\n",
    "            X = X_train[features_for_model[name]]\n",
    "            model = model.fit(X, y_train[\"scaled_target\"]) \n",
    "            prediction_df[name] = model.predict(test[features_for_model[name]])\n",
    "        prediction_df.index = test.index\n",
    "\n",
    "        #DUMMY VARIABLES FOR FINAL TRAIN AND TEST\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        onehot_encoded = (pd.get_dummies(train_result[\"sku\"]) > 0)\n",
    "        onehot = pd.DataFrame(onehot_encoded, index = train_result.index)\n",
    "\n",
    "        final_train = pd.concat([onehot,train_result[models.keys()]],axis = 1)\n",
    "\n",
    "        onehot_encoded = pd.get_dummies(y_test[\"sku\"]) > 0\n",
    "        onehot = pd.DataFrame(onehot_encoded, index = y_test.index).iloc[test.index]\n",
    "        final_test = pd.concat([onehot,prediction_df[models.keys()]],axis = 1)\n",
    "\n",
    "        #TRAIN ON TRAIN PREDICTIONS AND PREDICTION ON TEST PREDICTIONS\n",
    "        final_model.fit(final_train, y_train[\"scaled_target\"])\n",
    "        p =  final_model.predict(final_test)\n",
    "        final_prediction = np.append(final_prediction,p)\n",
    "        if rescale is not None:\n",
    "            print(\"MAPE %.5f\" % scaled_mape(final_prediction, y_test.loc[y_test.date == week], rescale))\n",
    "        X_train = pd.concat([X_train,test])\n",
    "        y_train = pd.concat([y_train,y_test.loc[y_test.date == week]])\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('processed_train.csv',index_col = 0)\n",
    "df_final_test = pd.read_csv('processed_test.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test.date = df_final_test.date.apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n",
    "df_train.date = df_train.date.apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n",
    "#df_train = df_train.loc[df_train.scope == 1]\n",
    "group1 = [688, 1058, 549, 546, 1027, 554, 1035, 1206, 1065]\n",
    "group2 = [144, 686, 1051]\n",
    "df_train = df_train.loc[df_train[\"sku\"].isin(group2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_df = pd.concat([df_train,df_final_test])[[\"target\",\"sku\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_df = df_train[['scaled_quarter','scaled_month','scaled_year','scaled_dayofyear','scaled_dayofmonth','scaled_weekofyear',\n",
    "             'scaled_price_diff1','scaled_price',\n",
    "            \"BRAND2\",\"BRAND4\",\n",
    "             'scaled_sales1','scaled_sales2','scaled_sales3','scaled_diff1','scaled_diff2','percentage_diff1',\n",
    "             \"scaled_rolling1\",\"scaled_rolling2\",\"scaled_rolling3\",\"scaled_rolling4\",\"scaled_rolling5\",\n",
    "             'scaled_promo',\n",
    "                     \"date\",\"sku\",\"scaled_target\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_df = simple_df.dropna().sort_values(by=[\"date\",\"sku\"]).set_index(\"date\")\n",
    "df_train = simple_df[:SplitTestDate].reset_index()\n",
    "df_test = simple_df[SplitTestDate:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>scaled_quarter</th>\n",
       "      <th>scaled_month</th>\n",
       "      <th>scaled_year</th>\n",
       "      <th>scaled_dayofyear</th>\n",
       "      <th>scaled_dayofmonth</th>\n",
       "      <th>scaled_weekofyear</th>\n",
       "      <th>scaled_price_diff1</th>\n",
       "      <th>scaled_price</th>\n",
       "      <th>BRAND2</th>\n",
       "      <th>...</th>\n",
       "      <th>percentage_diff1</th>\n",
       "      <th>scaled_rolling1</th>\n",
       "      <th>scaled_rolling2</th>\n",
       "      <th>scaled_rolling3</th>\n",
       "      <th>scaled_rolling4</th>\n",
       "      <th>scaled_rolling5</th>\n",
       "      <th>scaled_promo</th>\n",
       "      <th>sku</th>\n",
       "      <th>scaled_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933518</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347963</td>\n",
       "      <td>0.551038</td>\n",
       "      <td>0.442491</td>\n",
       "      <td>0.312314</td>\n",
       "      <td>0.248750</td>\n",
       "      <td>0.222983</td>\n",
       "      <td>0.997109</td>\n",
       "      <td>144</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>67124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933518</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.116822</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290672</td>\n",
       "      <td>0.549143</td>\n",
       "      <td>0.459704</td>\n",
       "      <td>0.329330</td>\n",
       "      <td>0.265112</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>686</td>\n",
       "      <td>0.523888</td>\n",
       "      <td>81178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933518</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.116822</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312015</td>\n",
       "      <td>0.561546</td>\n",
       "      <td>0.459901</td>\n",
       "      <td>0.334009</td>\n",
       "      <td>0.271925</td>\n",
       "      <td>0.240194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.555072</td>\n",
       "      <td>39461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.952909</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>-0.165939</td>\n",
       "      <td>0.340611</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103882</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>0.521681</td>\n",
       "      <td>0.459103</td>\n",
       "      <td>0.357317</td>\n",
       "      <td>0.297465</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>144</td>\n",
       "      <td>0.272244</td>\n",
       "      <td>40986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.952909</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>-0.210280</td>\n",
       "      <td>0.327103</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042795</td>\n",
       "      <td>0.523888</td>\n",
       "      <td>0.536516</td>\n",
       "      <td>0.481099</td>\n",
       "      <td>0.377970</td>\n",
       "      <td>0.316867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>686</td>\n",
       "      <td>0.247234</td>\n",
       "      <td>43122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445983</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.782033</td>\n",
       "      <td>0.097377</td>\n",
       "      <td>0.243170</td>\n",
       "      <td>0.495447</td>\n",
       "      <td>0.617814</td>\n",
       "      <td>0.624760</td>\n",
       "      <td>0.013526</td>\n",
       "      <td>686</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>22440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445983</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>-0.004673</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479149</td>\n",
       "      <td>0.104440</td>\n",
       "      <td>0.248235</td>\n",
       "      <td>0.480095</td>\n",
       "      <td>0.587022</td>\n",
       "      <td>0.570971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.116144</td>\n",
       "      <td>12610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465374</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.825328</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>0.066291</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.169012</td>\n",
       "      <td>0.358033</td>\n",
       "      <td>0.476649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>14119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465374</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>-0.004673</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.097130</td>\n",
       "      <td>0.194408</td>\n",
       "      <td>0.395806</td>\n",
       "      <td>0.513628</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>686</td>\n",
       "      <td>0.065936</td>\n",
       "      <td>18183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465374</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056780</td>\n",
       "      <td>0.116144</td>\n",
       "      <td>0.110292</td>\n",
       "      <td>0.204204</td>\n",
       "      <td>0.389107</td>\n",
       "      <td>0.492847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>8492.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  scaled_quarter  scaled_month  scaled_year  scaled_dayofyear  \\\n",
       "0  2018-12-08        1.000000      1.000000     0.666667          0.933518   \n",
       "1  2018-12-08        1.000000      1.000000     0.666667          0.933518   \n",
       "2  2018-12-08        1.000000      1.000000     0.666667          0.933518   \n",
       "3  2018-12-15        1.000000      1.000000     0.666667          0.952909   \n",
       "4  2018-12-15        1.000000      1.000000     0.666667          0.952909   \n",
       "..        ...             ...           ...          ...               ...   \n",
       "82 2019-06-15        0.333333      0.454545     1.000000          0.445983   \n",
       "83 2019-06-15        0.333333      0.454545     1.000000          0.445983   \n",
       "84 2019-06-22        0.333333      0.454545     1.000000          0.465374   \n",
       "85 2019-06-22        0.333333      0.454545     1.000000          0.465374   \n",
       "86 2019-06-22        0.333333      0.454545     1.000000          0.465374   \n",
       "\n",
       "    scaled_dayofmonth  scaled_weekofyear  scaled_price_diff1  scaled_price  \\\n",
       "0            0.233333           0.941176           -0.000000      0.174672   \n",
       "1            0.233333           0.941176           -0.000000      0.116822   \n",
       "2            0.233333           0.941176           -0.000000      0.116822   \n",
       "3            0.466667           0.960784           -0.165939      0.340611   \n",
       "4            0.466667           0.960784           -0.210280      0.327103   \n",
       "..                ...                ...                 ...           ...   \n",
       "82           0.466667           0.450980            0.004673      0.822430   \n",
       "83           0.466667           0.450980           -0.004673      0.817757   \n",
       "84           0.700000           0.470588           -0.000000      0.825328   \n",
       "85           0.700000           0.470588           -0.004673      0.827103   \n",
       "86           0.700000           0.470588            0.004673      0.813084   \n",
       "\n",
       "    BRAND2  ...  percentage_diff1  scaled_rolling1  scaled_rolling2  \\\n",
       "0     True  ...         -0.347963         0.551038         0.442491   \n",
       "1    False  ...         -0.290672         0.549143         0.459704   \n",
       "2    False  ...         -0.312015         0.561546         0.459901   \n",
       "3     True  ...          0.103882         0.492325         0.521681   \n",
       "4    False  ...          0.042795         0.523888         0.536516   \n",
       "..     ...  ...               ...              ...              ...   \n",
       "82   False  ...          1.782033         0.097377         0.243170   \n",
       "83   False  ...          1.479149         0.104440         0.248235   \n",
       "84    True  ...         -0.001997         0.066291         0.066152   \n",
       "85   False  ...          0.003030         0.096883         0.097130   \n",
       "86   False  ...         -0.056780         0.116144         0.110292   \n",
       "\n",
       "    scaled_rolling3  scaled_rolling4  scaled_rolling5  scaled_promo   sku  \\\n",
       "0          0.312314         0.248750         0.222983      0.997109   144   \n",
       "1          0.329330         0.265112         0.235700      1.000000   686   \n",
       "2          0.334009         0.271925         0.240194      1.000000  1051   \n",
       "3          0.459103         0.357317         0.297465      0.985455   144   \n",
       "4          0.481099         0.377970         0.316867      1.000000   686   \n",
       "..              ...              ...              ...           ...   ...   \n",
       "82         0.495447         0.617814         0.624760      0.013526   686   \n",
       "83         0.480095         0.587022         0.570971      0.000000  1051   \n",
       "84         0.169012         0.358033         0.476649      0.000000   144   \n",
       "85         0.194408         0.395806         0.513628      0.008066   686   \n",
       "86         0.204204         0.389107         0.492847      0.000000  1051   \n",
       "\n",
       "    scaled_target   target  \n",
       "0        0.492325  67124.0  \n",
       "1        0.523888  81178.0  \n",
       "2        0.555072  39461.0  \n",
       "3        0.272244  40986.0  \n",
       "4        0.247234  43122.0  \n",
       "..            ...      ...  \n",
       "82       0.096883  22440.0  \n",
       "83       0.116144  12610.0  \n",
       "84       0.046024  14119.0  \n",
       "85       0.065936  18183.0  \n",
       "86       0.048828   8492.0  \n",
       "\n",
       "[87 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['scaled_quarter','scaled_month','scaled_year','scaled_dayofyear','scaled_dayofmonth','scaled_weekofyear',\n",
    "             'scaled_price_diff1','scaled_price',\n",
    "            \"BRAND2\",\"BRAND4\",\n",
    "             'scaled_sales1','scaled_sales2','scaled_sales3','scaled_diff1','scaled_diff2','percentage_diff1',\n",
    "             \"scaled_rolling1\",\"scaled_rolling2\",\"scaled_rolling3\",\"scaled_rolling4\",\"scaled_rolling5\",\n",
    "             'scaled_promo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[[\"date\",\"sku\",\"scaled_target\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['scaled_quarter','scaled_month','scaled_year','scaled_dayofyear','scaled_dayofmonth','scaled_weekofyear',\n",
    "             'scaled_price_diff1','scaled_price',\n",
    "            \"BRAND2\",\"BRAND4\",\n",
    "             'scaled_sales1','scaled_sales2','scaled_sales3','scaled_diff1','scaled_diff2','percentage_diff1',\n",
    "             \"scaled_rolling1\",\"scaled_rolling2\",\"scaled_rolling3\",\"scaled_rolling4\",\"scaled_rolling5\",\n",
    "             'scaled_promo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test[[\"date\",\"sku\",\"scaled_target\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sku</th>\n",
       "      <th>scaled_target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>144</td>\n",
       "      <td>0.272244</td>\n",
       "      <td>40986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>686</td>\n",
       "      <td>0.247234</td>\n",
       "      <td>43122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.276637</td>\n",
       "      <td>22428.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   sku  scaled_target   target\n",
       "3 2018-12-15   144       0.272244  40986.0\n",
       "4 2018-12-15   686       0.247234  43122.0\n",
       "5 2018-12-15  1051       0.276637  22428.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_test.loc[y_test.date == \"2018-12-15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-08T00:00:00.000000000\n",
      "MAPE 15.12635\n",
      "2018-12-15T00:00:00.000000000\n",
      "MAPE 102.06860\n",
      "2018-12-22T00:00:00.000000000\n",
      "MAPE 292.03043\n",
      "2018-12-29T00:00:00.000000000\n",
      "MAPE 615.32272\n",
      "2019-01-05T00:00:00.000000000\n",
      "MAPE 383.97156\n",
      "2019-01-12T00:00:00.000000000\n",
      "MAPE 15.61011\n",
      "2019-01-19T00:00:00.000000000\n",
      "MAPE 23.69227\n",
      "2019-01-26T00:00:00.000000000\n",
      "MAPE 28.02574\n",
      "2019-02-02T00:00:00.000000000\n",
      "MAPE 33.36502\n",
      "2019-02-09T00:00:00.000000000\n",
      "MAPE 211.16223\n",
      "2019-02-16T00:00:00.000000000\n",
      "MAPE 311.69210\n",
      "2019-02-23T00:00:00.000000000\n",
      "MAPE 413.08348\n",
      "2019-03-02T00:00:00.000000000\n",
      "MAPE 381.94972\n",
      "2019-03-09T00:00:00.000000000\n",
      "MAPE 45.77577\n",
      "2019-03-16T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "res = StackingPred(models,finalreg, X_train, y_train, X_test,y_test,features_for_model,rescale = rescale_df, span = 9, label = \"scaled_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = res.set_index(res[\"i\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape,results = plot_scaled_results(res, y_test, rescale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
